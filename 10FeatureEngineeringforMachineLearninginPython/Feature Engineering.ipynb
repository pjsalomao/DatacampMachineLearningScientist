{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for Machine Learning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Description\n",
    "Every day you read about the amazing breakthroughs in how the newest applications of machine learning are changing the world. Often this reporting glosses over the fact that a huge amount of data munging and feature engineering must be done before any of these fancy models can be used. In this course, you will learn how to do just that. You will work with Stack Overflow Developers survey, and historic US presidential inauguration addresses, to understand how best to preprocess and engineer features from categorical, continuous, and unstructured data. This course will give you hands-on experience on how to prepare any data for your own machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Features\n",
    "In this chapter, you will explore what feature engineering is and how to get started with applying it to real-world data. You will load, explore and visualize a survey response dataset, and in doing so you will learn about its underlying data types and why they have an influence on how you should engineer your features. Using the pandas package you will create new features from both categorical and continuous columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting to know your data\n",
    "Pandas is one the most popular packages used to work with tabular data in Python. It is generally imported using the alias pd and can be used to load a CSV (or other delimited files) using read_csv().\n",
    "\n",
    "You will be working with a modified subset of the Stackoverflow survey response data in the first three chapters of this course. This data set records the details, and preferences of thousands of users of the StackOverflow website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SurveyDate</th>\n",
       "      <th>FormalEducation</th>\n",
       "      <th>ConvertedSalary</th>\n",
       "      <th>Hobby</th>\n",
       "      <th>Country</th>\n",
       "      <th>StackOverflowJobsRecommend</th>\n",
       "      <th>VersionControl</th>\n",
       "      <th>Age</th>\n",
       "      <th>Years Experience</th>\n",
       "      <th>Gender</th>\n",
       "      <th>RawSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/28/18 20:20</td>\n",
       "      <td>Bachelor's degree (BA. BS. B.Eng.. etc.)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Git</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/28/18 13:26</td>\n",
       "      <td>Bachelor's degree (BA. BS. B.Eng.. etc.)</td>\n",
       "      <td>70841.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sweeden</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Git;Subversion</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>Male</td>\n",
       "      <td>70,841.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/6/18 3:37</td>\n",
       "      <td>Bachelor's degree (BA. BS. B.Eng.. etc.)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>Sweeden</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Git</td>\n",
       "      <td>45</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/9/18 1:06</td>\n",
       "      <td>Some college/university study without earning ...</td>\n",
       "      <td>21426.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Sweeden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zip file back-ups</td>\n",
       "      <td>46</td>\n",
       "      <td>12</td>\n",
       "      <td>Male</td>\n",
       "      <td>21,426.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/12/18 22:41</td>\n",
       "      <td>Bachelor's degree (BA. BS. B.Eng.. etc.)</td>\n",
       "      <td>41671.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>UK</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Git</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>Male</td>\n",
       "      <td>£41,671.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SurveyDate                                    FormalEducation  \\\n",
       "0  2/28/18 20:20           Bachelor's degree (BA. BS. B.Eng.. etc.)   \n",
       "1  6/28/18 13:26           Bachelor's degree (BA. BS. B.Eng.. etc.)   \n",
       "2    6/6/18 3:37           Bachelor's degree (BA. BS. B.Eng.. etc.)   \n",
       "3    5/9/18 1:06  Some college/university study without earning ...   \n",
       "4  4/12/18 22:41           Bachelor's degree (BA. BS. B.Eng.. etc.)   \n",
       "\n",
       "   ConvertedSalary Hobby       Country  StackOverflowJobsRecommend  \\\n",
       "0              NaN   Yes  South Africa                         NaN   \n",
       "1          70841.0   Yes       Sweeden                         7.0   \n",
       "2              NaN    No       Sweeden                         8.0   \n",
       "3          21426.0   Yes       Sweeden                         NaN   \n",
       "4          41671.0   Yes            UK                         8.0   \n",
       "\n",
       "      VersionControl  Age  Years Experience Gender   RawSalary  \n",
       "0                Git   21                13   Male         NaN  \n",
       "1     Git;Subversion   38                 9   Male   70,841.00  \n",
       "2                Git   45                11    NaN         NaN  \n",
       "3  Zip file back-ups   46                12   Male   21,426.00  \n",
       "4                Git   39                 7   Male  £41,671.00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Import so_survey_csv into so_survey_df\n",
    "so_survey_df = pd.read_csv('datasets/Combined_DS_v10.csv')\n",
    "\n",
    "# Print the first five rows of the DataFrame\n",
    "so_survey_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SurveyDate                     object\n",
       "FormalEducation                object\n",
       "ConvertedSalary               float64\n",
       "Hobby                          object\n",
       "Country                        object\n",
       "StackOverflowJobsRecommend    float64\n",
       "VersionControl                 object\n",
       "Age                             int64\n",
       "Years Experience                int64\n",
       "Gender                         object\n",
       "RawSalary                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Print the data type of each column\n",
    "so_survey_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting specific data types\n",
    "Often a data set will contain columns with several different data types (like the one you are working with). The majority of machine learning models require you to have a consistent data type across features. Similarly, most feature engineering techniques are applicable to only one type of data at a time. For these reasons among others, you will often want to be able to access just the columns of certain types when working with a DataFrame.\n",
    "\n",
    "The DataFrame (so_survey_df) from the previous exercise is available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ConvertedSalary', 'StackOverflowJobsRecommend', 'Age',\n",
      "       'Years Experience'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create subset of only the numeric columns\n",
    "so_numeric_df = so_survey_df.select_dtypes(include=['int', 'float'])\n",
    "\n",
    "# Print the column names contained in so_survey_df_num\n",
    "print(so_numeric_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding and dummy variables\n",
    "To use categorical variables in a machine learning model, you first need to represent them in a quantitative way. The two most common approaches are to one-hot encode the variables using or to use dummy variables. In this exercise, you will create both types of encoding, and compare the created column sets. We will continue using the same DataFrame from previous lesson loaded as so_survey_df and focusing on its Country column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SurveyDate', 'FormalEducation', 'ConvertedSalary', 'Hobby',\n",
      "       'StackOverflowJobsRecommend', 'VersionControl', 'Age',\n",
      "       'Years Experience', 'Gender', 'RawSalary', 'OH_France', 'OH_India',\n",
      "       'OH_Ireland', 'OH_Russia', 'OH_South Africa', 'OH_Spain', 'OH_Sweeden',\n",
      "       'OH_UK', 'OH_USA', 'OH_Ukraine'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Convert the Country column to a one hot encoded Data Frame\n",
    "one_hot_encoded = pd.get_dummies(so_survey_df, columns=['Country'], prefix='OH')\n",
    "\n",
    "# Print the columns names\n",
    "print(one_hot_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SurveyDate', 'FormalEducation', 'ConvertedSalary', 'Hobby',\n",
      "       'StackOverflowJobsRecommend', 'VersionControl', 'Age',\n",
      "       'Years Experience', 'Gender', 'RawSalary', 'DM_India', 'DM_Ireland',\n",
      "       'DM_Russia', 'DM_South Africa', 'DM_Spain', 'DM_Sweeden', 'DM_UK',\n",
      "       'DM_USA', 'DM_Ukraine'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create dummy variables for the Country column\n",
    "dummy = pd.get_dummies(so_survey_df, columns=['Country'], drop_first=True, prefix='DM')\n",
    "\n",
    "# Print the columns names\n",
    "print(dummy.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with uncommon categories\n",
    "Some features can have many different categories but a very uneven distribution of their occurrences. Take for example Data Science's favorite languages to code in, some common choices are Python, R, and Julia, but there can be individuals with bespoke choices, like FORTRAN, C etc. In these cases, you may not want to create a feature for each value, but only the more common occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South Africa    166\n",
      "USA             164\n",
      "Spain           134\n",
      "Sweeden         119\n",
      "France          115\n",
      "Russia           97\n",
      "UK               95\n",
      "India            95\n",
      "Ukraine           9\n",
      "Ireland           5\n",
      "Name: Country, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a series out of the Country column\n",
    "countries = so_survey_df['Country']\n",
    "\n",
    "# Get the counts of each category\n",
    "country_counts = countries.value_counts()\n",
    "\n",
    "# Print the count values for each category\n",
    "print(country_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: Country, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Create a series out of the Country column\n",
    "countries = so_survey_df['Country']\n",
    "\n",
    "# Get the counts of each category\n",
    "country_counts = countries.value_counts()\n",
    "\n",
    "# Create a mask for only categories that occur less than 10 times\n",
    "mask = countries.isin(country_counts[country_counts < 10].index)\n",
    "\n",
    "# Print the top 5 rows in the mask series\n",
    "print(mask.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South Africa    166\n",
      "USA             164\n",
      "Spain           134\n",
      "Sweeden         119\n",
      "France          115\n",
      "Russia           97\n",
      "UK               95\n",
      "India            95\n",
      "Other            14\n",
      "Name: Country, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsntos/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Create a series out of the Country column\n",
    "countries = so_survey_df['Country']\n",
    "\n",
    "# Get the counts of each category\n",
    "country_counts = countries.value_counts()\n",
    "\n",
    "# Create a mask for only categories that occur less than 10 times\n",
    "mask = countries.isin(country_counts[country_counts < 10].index)\n",
    "\n",
    "# Label all other categories as Other\n",
    "countries[mask] = 'Other'\n",
    "\n",
    "# Print the updated category counts\n",
    "print(pd.value_counts(countries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarizing columns\n",
    "While numeric values can often be used without any feature engineering, there will be cases when some form of manipulation can be useful. For example on some occasions, you might not care about the magnitude of a value but only care about its direction, or if it exists at all. In these situations, you will want to binarize a column. In the so_survey_df data, you have a large number of survey respondents that are working voluntarily (without pay). You will create a new column titled Paid_Job indicating whether each person is paid (their salary is greater than zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paid_Job</th>\n",
       "      <th>ConvertedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>70841.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>21426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>41671.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Paid_Job  ConvertedSalary\n",
       "0         0              NaN\n",
       "1         1          70841.0\n",
       "2         0              NaN\n",
       "3         1          21426.0\n",
       "4         1          41671.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Paid_Job column filled with zeros\n",
    "so_survey_df['Paid_Job'] = 0\n",
    "\n",
    "# Replace all the Paid_Job values where ConvertedSalary is > 0\n",
    "so_survey_df.loc[so_survey_df['ConvertedSalary'] > 0, 'Paid_Job'] = 1\n",
    "\n",
    "# Print the first five rows of the columns\n",
    "so_survey_df[['Paid_Job', 'ConvertedSalary']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning values\n",
    "For many continuous values you will care less about the exact value of a numeric column, but instead care about the bucket it falls into. This can be useful when plotting values, or simplifying your machine learning models. It is mostly used on continuous variables where accuracy is not the biggest concern e.g. age, height, wages.\n",
    "\n",
    "Bins are created using pd.cut(df['column_name'], bins) where bins can be an integer specifying the number of evenly spaced bins, or a list of bin boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          equal_binned  ConvertedSalary\n",
      "0                  NaN              NaN\n",
      "1  (-2000.0, 400000.0]          70841.0\n",
      "2                  NaN              NaN\n",
      "3  (-2000.0, 400000.0]          21426.0\n",
      "4  (-2000.0, 400000.0]          41671.0\n"
     ]
    }
   ],
   "source": [
    "# Bin the continuous variable ConvertedSalary into 5 bins\n",
    "so_survey_df['equal_binned'] = pd.cut(so_survey_df['ConvertedSalary'], 5)\n",
    "\n",
    "# Print the first 5 rows of the equal_binned column\n",
    "print(so_survey_df[['equal_binned', 'ConvertedSalary']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import numpy\n",
    "# import numpy as np\n",
    "\n",
    "# # Specify the boundaries of the bins\n",
    "# bins = [-np.inf, 10000, 50000, 100000, 150000, np.inf]\n",
    "\n",
    "# # Bin labels\n",
    "# labels = ['Very low', 'Low', 'Medium', 'High', 'Very high']\n",
    "\n",
    "# # Bin the continuous variable ConvertedSalary using these boundaries\n",
    "# so_survey_df['boundary_binned'] = pd.cut(so_survey_df['ConvertedSalary'], \n",
    "#                                          bins, labels)\n",
    "\n",
    "# # Print the first 5 rows of the boundary_binned column\n",
    "# print(so_survey_df[['boundary_binned', 'ConvertedSalary']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How sparse is my data?\n",
    "Most data sets contain missing values, often represented as NaN (Not a Number). If you are working with Pandas you can easily check how many missing values exist in each column.\n",
    "\n",
    "Let's find out how many of the developers taking the survey chose to enter their age (found in the Age column of so_survey_df) and their gender (Gender column of so_survey_df)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999 entries, 0 to 998\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Age     999 non-null    int64 \n",
      " 1   Gender  693 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Subset the DataFrame\n",
    "sub_df = so_survey_df[['Age', 'Gender']]\n",
    "\n",
    "# Print the number of non-missing values\n",
    "print(sub_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the missing values\n",
    "While having a summary of how much of your data is missing can be useful, often you will need to find the exact locations of these missing values. Using the same subset of the StackOverflow data from the last exercise (sub_df), you will show how a value can be flagged as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top 10 entries of the DataFrame\n",
    "print(sub_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the locations of the missing values\n",
    "print(sub_df.head(10).())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Gender\n",
      "0  True    True\n",
      "1  True    True\n",
      "2  True   False\n",
      "3  True    True\n",
      "4  True    True\n",
      "5  True    True\n",
      "6  True    True\n",
      "7  True    True\n",
      "8  True    True\n",
      "9  True   False\n"
     ]
    }
   ],
   "source": [
    "# Print the locations of the non-missing values\n",
    "print(sub_df.head(10).notnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listwise deletion\n",
    "The simplest way to deal with missing values in your dataset when they are occurring entirely at random is to remove those rows, also called 'listwise deletion'.\n",
    "\n",
    "Depending on the use case, you will sometimes want to remove all missing values in your data while other times you may want to only remove a particular column if too many values are missing in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 13)\n"
     ]
    }
   ],
   "source": [
    "# Print the number of rows and columns\n",
    "print(so_survey_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 13)\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame dropping all incomplete rows\n",
    "no_missing_values_rows = so_survey_df.dropna(axis=0)\n",
    "\n",
    "# Print the shape of the new DataFrame\n",
    "print(no_missing_values_rows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 8)\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame dropping all columns with incomplete rows\n",
    "no_missing_values_cols = so_survey_df.dropna( axis=1)\n",
    "\n",
    "# Print the shape of the new DataFrame\n",
    "print(no_missing_values_cols.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(693, 13)\n"
     ]
    }
   ],
   "source": [
    "# Drop all rows where Gender is missing\n",
    "no_gender = so_survey_df.dropna(subset=['Gender'])\n",
    "\n",
    "# Print the shape of the new DataFrame\n",
    "print(no_gender.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing missing values with constants\n",
    "While removing missing data entirely maybe a correct approach in many situations, this may result in a lot of information being omitted from your models.\n",
    "\n",
    "You may find categorical columns where the missing value is a valid piece of information in itself, such as someone refusing to answer a question in a survey. In these cases, you can fill all missing values with a new category entirely, for example 'No response given'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male                                                                         632\n",
      "Female                                                                        53\n",
      "Transgender                                                                    2\n",
      "Female;Male                                                                    2\n",
      "Female;Male;Transgender;Non-binary. genderqueer. or gender non-conforming      1\n",
      "Female;Transgender                                                             1\n",
      "Non-binary. genderqueer. or gender non-conforming                              1\n",
      "Male;Non-binary. genderqueer. or gender non-conforming                         1\n",
      "Name: Gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the count of occurrences\n",
    "print(so_survey_df['Gender'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male                                                                         632\n",
      "Not Given                                                                    306\n",
      "Female                                                                        53\n",
      "Transgender                                                                    2\n",
      "Female;Male                                                                    2\n",
      "Female;Male;Transgender;Non-binary. genderqueer. or gender non-conforming      1\n",
      "Female;Transgender                                                             1\n",
      "Non-binary. genderqueer. or gender non-conforming                              1\n",
      "Male;Non-binary. genderqueer. or gender non-conforming                         1\n",
      "Name: Gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace missing values\n",
    "so_survey_df['Gender'].fillna('Not Given', inplace=True)\n",
    "\n",
    "# Print the count of each value\n",
    "print(so_survey_df['Gender'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling continuous missing values\n",
    "In the last lesson, you dealt with different methods of removing data missing values and filling in missing values with a fixed string. These approaches are valid in many cases, particularly when dealing with categorical columns but have limited use when working with continuous values. In these cases, it may be most valid to fill the missing values in the column with a value calculated from the entries present in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first five rows of StackOverflowJobsRecommend column\n",
    "print(so_survey_df['StackOverflowJobsRecommend'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7.061602\n",
      "1    7.000000\n",
      "2    8.000000\n",
      "3    7.061602\n",
      "4    8.000000\n",
      "Name: StackOverflowJobsRecommend, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with the mean\n",
    "so_survey_df['StackOverflowJobsRecommend'].fillna(so_survey_df['StackOverflowJobsRecommend'].mean(), inplace=True)\n",
    "\n",
    "# Print the first five rows of StackOverflowJobsRecommend column\n",
    "print(so_survey_df['StackOverflowJobsRecommend'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7.0\n",
      "1    7.0\n",
      "2    8.0\n",
      "3    7.0\n",
      "4    8.0\n",
      "Name: StackOverflowJobsRecommend, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with the mean\n",
    "so_survey_df['StackOverflowJobsRecommend'].fillna(so_survey_df['StackOverflowJobsRecommend'].mean(), inplace=True)\n",
    "\n",
    "# Round the StackOverflowJobsRecommend values\n",
    "so_survey_df['StackOverflowJobsRecommend'] = round(so_survey_df['StackOverflowJobsRecommend'])\n",
    "\n",
    "# Print the top 5 rows\n",
    "print(so_survey_df['StackOverflowJobsRecommend'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with stray characters (I)\n",
    "In this exercise, you will work with the RawSalary column of so_survey_df which contains the wages of the respondents along with the currency symbols and commas, such as $42,000. When importing data from Microsoft Excel, more often that not you will come across data in this form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the commas in the column\n",
    "so_survey_df['RawSalary'] = so_survey_df['RawSalary'].str.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the dollar signs in the column\n",
    "so_survey_df['RawSalary'] = so_survey_df['RawSalary'].str.replace('$', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with stray characters (II)\n",
    "In the last exercise, you could tell quickly based off of the df.head() call which characters were causing an issue. In many cases this will not be so apparent. There will often be values deep within a column that are preventing you from casting a column as a numeric type so that it can be used in a model or further feature engineering.\n",
    "\n",
    "One approach to finding these values is to force the column to the data type desired using pd.to_numeric(), coercing any values causing issues to NaN, Then filtering the DataFrame by just the rows containing the NaN values.\n",
    "\n",
    "Try to cast the RawSalary column as a float and it will fail as an additional character can now be found in it. Find the character and remove it so the column can be cast as a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      NaN\n",
      "2      NaN\n",
      "6      NaN\n",
      "8      NaN\n",
      "11     NaN\n",
      "      ... \n",
      "989    NaN\n",
      "990    NaN\n",
      "992    NaN\n",
      "994    NaN\n",
      "997    NaN\n",
      "Name: RawSalary, Length: 334, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Attempt to convert the column to numeric values\n",
    "numeric_vals = pd.to_numeric(so_survey_df['RawSalary'], errors='coerce')\n",
    "\n",
    "# Find the indexes of missing values\n",
    "idx = numeric_vals.isna()\n",
    "\n",
    "# Print the relevant rows\n",
    "print(so_survey_df['RawSalary'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            NaN\n",
      "1        70841.0\n",
      "2            NaN\n",
      "3        21426.0\n",
      "4        41671.0\n",
      "         ...    \n",
      "994          NaN\n",
      "995      58746.0\n",
      "996      55000.0\n",
      "997          NaN\n",
      "998    1000000.0\n",
      "Name: RawSalary, Length: 999, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Replace the offending characters\n",
    "so_survey_df['RawSalary'] = so_survey_df['RawSalary'].str.replace('£', '')\n",
    "\n",
    "# Convert the column to float\n",
    "so_survey_df['RawSalary'] = so_survey_df['RawSalary'].astype(float)\n",
    "# Print the column\n",
    "print(so_survey_df['RawSalary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method chaining\n",
    "When applying multiple operations on the same column (like in the previous exercises), you made the changes in several steps, assigning the results back in each step. However, when applying multiple successive operations on the same column, you can \"chain\" these operations together for clarity and ease of management. This can be achieved by calling multiple methods sequentially:\n",
    "\n",
    "    # Method chaining\n",
    "    df['column'] = df['column'].method1().method2().method3()\n",
    "\n",
    "    # Same as \n",
    "    df['column'] = df['column'].method1()\n",
    "    df['column'] = df['column'].method2()\n",
    "    df['column'] = df['column'].method3()\n",
    "In this exercise you will repeat the steps you performed in the last two exercises, but do so using method chaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import so_survey_csv into so_survey_df\n",
    "so_survey_df = pd.read_csv('datasets/Combined_DS_v10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            NaN\n",
      "1        70841.0\n",
      "2            NaN\n",
      "3        21426.0\n",
      "4        41671.0\n",
      "         ...    \n",
      "994          NaN\n",
      "995      58746.0\n",
      "996      55000.0\n",
      "997          NaN\n",
      "998    1000000.0\n",
      "Name: RawSalary, Length: 999, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Use method chaining\n",
    "so_survey_df['RawSalary'] = so_survey_df['RawSalary']\\\n",
    "                              .str.replace(',','')\\\n",
    "                              .str.replace('$', '')\\\n",
    "                              .str.replace('£', '')\\\n",
    "                              .astype(float)\n",
    " \n",
    "# Print the RawSalary column\n",
    "print(so_survey_df['RawSalary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
